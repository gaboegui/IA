{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Universidad Internacional de La Rioja (UNIR) - Máster Universitario en Inteligencia Artificial - Procesamiento del Lenguaje Natural** \n",
    "\n",
    "\n",
    "# Laboratorio: Desambiguación del sentido de las palabras\n",
    "\n",
    "\n",
    "**Objetivos**\n",
    "\n",
    "Con este laboratorio el alumno conseguirá aplicar diferentes algoritmos basados en aprendizaje automático supervisado para desambiguar el sentido de las palabras. Además, va a aprender a utilizar la herramienta de software abierto Natural Language Toolkit (NLTK) con la que implementar tareas de procesamiento del lenguaje natural en Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer paso es importar el corpus etiquetado utilizando los siguientes comandos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import senseval\n",
    "\n",
    "#nltk.download('senseval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El corpus Senseval 2 contiene datos etiquetados que sirven para entrenar un clasificador que permita desambiguar el sentido de las palabras. Cada elemento del corpus Senseval 2 se corresponde a una palabra ambigua, concretamente a las palabras en inglés *«hard»*, *«interest»*, *«line»* y *«serve»*, tal como se observa a través del siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hard.pos', 'interest.pos', 'line.pos', 'serve.pos']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senseval.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: análisis del corpus\n",
    "\n",
    "Analiza el corpus Senseval 2 que vas a utilizar para entrenar los clasificadores. Para realizar el análisis utiliza las funcionalidades que aporta NLTK. Desarrolla el código necesario y responde a las siguientes preguntas.\n",
    "\n",
    "* ¿Cuántos posibles sentidos tiene cada palabra ambigua? ¿Cuáles son esos sentidos? Para cada sentido indica la etiqueta que aparece en el corpus y su definición según WordNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HARD3', 'HARD2', 'HARD1'}\n",
      "{'interest_2', 'interest_5', 'interest_1', 'interest_4', 'interest_6', 'interest_3'}\n",
      "{'phone', 'cord', 'product', 'formation', 'text', 'division'}\n",
      "{'SERVE6', 'SERVE2', 'SERVE12', 'SERVE10'}\n"
     ]
    }
   ],
   "source": [
    "def getSentidos(amb_word):\n",
    "    senses = set()\n",
    "    for inst in senseval.instances(amb_word):\n",
    "        senses.add(inst.senses[0])\n",
    "    return senses\n",
    "\n",
    "# 'hard.pos', 'interest.pos', 'line.pos', 'serve.pos'\n",
    "print(getSentidos('hard.pos'))\n",
    "print(getSentidos('interest.pos'))\n",
    "print(getSentidos('line.pos'))\n",
    "print(getSentidos('serve.pos'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESPUESTA\n",
    "\n",
    "*Etiqueta del Corpus: DEFINICION EN WORDNET*\n",
    "\n",
    "\n",
    "#### Hard\n",
    "- HARD1: (not easy; requiring great physical or mental effort to accomplish or comprehend or endure)\n",
    "- HARD2: (dispassionate) \n",
    "- HARD3: (resisting weight or pressure)\n",
    "\n",
    "#### Interest\n",
    "- interest_1: (a sense of concern with and curiosity about someone or something)\n",
    "- interest_2: (a reason for wanting something done)\n",
    "- interest_3: (the power of attracting or holding one's attention (because it is unusual or exciting etc.)) \n",
    "- interest_4: (a fixed charge for borrowing money; usually a percentage of the amount borrowed) \n",
    "- interest_5: ((law) a right or legal share of something; a financial involvement with something)\n",
    "- interest_6: ((usually plural) a social group whose members control some field of activity and who have common aims)\n",
    "\n",
    "#### Line\n",
    "- cord: (something (as a cord or rope) that is long and thin and flexible) \"a washing line\"\n",
    "- division: (a mark that is long relative to its width)\n",
    "- formation: (a formation of people or things one beside another)\n",
    "- phone: (a telephone connection)\n",
    "- product: (a particular kind of product or merchandise)\n",
    "- text: (text consisting of a row of words written across a page or computer screen)\n",
    "\n",
    "#### Serve\n",
    "- SERVE10: (work for or be a servant to)\n",
    "- SERVE12: (be sufficient; be adequate, either in quality or quantity)\n",
    "- SERVE2: (do duty or hold offices; serve in a specific function)\n",
    "- SERVE6: (provide (usually but not necessarily food))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Cuántas instancias hay en el corpus para cada uno de los sentidos de las palabras ambiguas? Es decir, cuantas oraciones hay en el corpus etiquetadas con cada uno de los sentidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HARD3': 376, 'HARD2': 502, 'HARD1': 3455, 'suma': 4333}\n",
      "{'interest_2': 11, 'interest_5': 500, 'interest_1': 361, 'interest_4': 178, 'interest_6': 1252, 'interest_3': 66, 'suma': 2368}\n",
      "{'phone': 429, 'cord': 373, 'product': 2217, 'formation': 349, 'text': 404, 'division': 374, 'suma': 4146}\n",
      "{'SERVE6': 439, 'SERVE2': 853, 'SERVE12': 1272, 'SERVE10': 1814, 'suma': 4378}\n"
     ]
    }
   ],
   "source": [
    "# funcion que cuenta cuantas oraciones hay de cada sentido\n",
    "# además obtiene un valor total para comprobar que coincida con el total de palabras\n",
    "# cuando se ejecuta len(senseval.instances(amb_word)) \n",
    "def contarInstanciasDeCadaSentido(amb_word):\n",
    "    resultado = {}\n",
    "    suma = 0\n",
    "    # creo el conjunto de los sentidos de cada palabra\n",
    "    for sense in getSentidos(amb_word):\n",
    "        cont=0\n",
    "        for inst in senseval.instances(amb_word):\n",
    "            if sense == inst.senses[0]:\n",
    "                cont+=1\n",
    "                suma+=1\n",
    "            resultado[sense] = cont\n",
    "    resultado['suma'] = suma\n",
    "    return resultado\n",
    "\n",
    "print(contarInstanciasDeCadaSentido('hard.pos'))\n",
    "print(contarInstanciasDeCadaSentido('interest.pos'))\n",
    "print(contarInstanciasDeCadaSentido('line.pos'))\n",
    "print(contarInstanciasDeCadaSentido('serve.pos'))\n",
    "#len(senseval.instances('hard.pos'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En el contexto, las palabras ambiguas pueden aparecer en diferentes formas gramaticales. Por ejemplo, en el caso de la palabra ambigua *«hard»*, esta aparece tanto la forma base, el adjetivo *«hard»* como en comparativo *«harder»* y como en superlativo *«hardest»*. ¿Qué formas gramaticales aparecen en el contexto para cada una de las palabas ambiguas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion para obtener las formas gramaticales pertenecientes a cada palabra\n",
    "def getFormasGram(amb_word):\n",
    "    formas = set()\n",
    "    for inst in senseval.instances(amb_word):\n",
    "        formas.add(inst.context[inst.position][0])\n",
    "    return formas\n",
    "\n",
    "formas = getFormasGram('hard.pos')\n",
    "formas2 = getFormasGram('interest.pos')\n",
    "formas3 = getFormasGram('line.pos')\n",
    "formas4 = getFormasGram('serve.pos')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respuesta \n",
    "las distintas formas gramaticales del corpus, para cada una de las palabras ambiguas son las siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hard', 'hardest', 'harder'} \n",
      "\n",
      " {'interests', 'interest'} \n",
      "\n",
      " {'line', 'lined', 'lines'} \n",
      "\n",
      " {'served', 'serving', 'serve', 'serves'} \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (formas,'\\n\\n', formas2,'\\n\\n', formas3,'\\n\\n', formas4,'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Tienen todas las instancias que forman el corpus el formato que se ha descrito anteriormente? Si hay alguna instancia que no cumpla con ese formato, indica cuales serían las incongruencias que presenta y muestra algunos ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins = senseval.instances('hard.pos')[999]\n",
    "type(ins.context) # es una lista\n",
    "type(ins.context[0]) # normalmente debería ser una tupla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprimeOracion(lista):\n",
    "    oracion = ''\n",
    "    for item in lista:\n",
    "        oracion+=item[0] + ' '\n",
    "    return oracion\n",
    "\n",
    "# Detecta incongruencia en la notacion del contexto, es decir cuando no existe \n",
    "# una tupla compuesta por la palabra y su etiqueta POS\n",
    "def encuentraIncongruenciasContexto(amb_word, mostrar = False):\n",
    "    i=-1\n",
    "    numeros = set()\n",
    "    for inst in senseval.instances(amb_word):\n",
    "        lista = inst.context\n",
    "        i=i+1\n",
    "        for pairwords in lista:\n",
    "            if type(pairwords) is not tuple:\n",
    "                #si se quiere ver cual es la palabra y la instancia\n",
    "                if mostrar== True:\n",
    "                    print(pairwords, 'instancia:', i)\n",
    "                numeros.add(i)\n",
    "    return numeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instancias en hard.pos: [21, 110, 196, 892, 999, 1010, 1028, 1088, 1170, 1351, 1807, 2452, 2602, 2700, 2899, 3225, 4030, 4058, 4090]\n",
      "Numero total de incosistencias en hard.pos 19\n"
     ]
    }
   ],
   "source": [
    "instanciasconerror = encuentraIncongruenciasContexto('hard.pos')\n",
    "print('Instancias en hard.pos:', sorted(instanciasconerror))\n",
    "print('Numero total de incosistencias en hard.pos', len(instanciasconerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instancias en interest.pos: []\n",
      "Numero total de incosistencias en interest.pos 0\n"
     ]
    }
   ],
   "source": [
    "# 'interest.pos'\n",
    "instanciasconerror = encuentraIncongruenciasContexto('interest.pos')\n",
    "print('Instancias en interest.pos:', sorted(instanciasconerror))\n",
    "print('Numero total de incosistencias en interest.pos', len(instanciasconerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRASL instancia: 324\n",
      "FRASL instancia: 391\n",
      "to instancia: 517\n",
      "spending instancia: 517\n",
      "the instancia: 559\n",
      "Houston instancia: 559\n",
      "suburb instancia: 559\n",
      "of instancia: 559\n",
      "FRASL instancia: 644\n",
      "FRASL instancia: 681\n",
      "FRASL instancia: 681\n",
      "FRASL instancia: 910\n",
      "in instancia: 986\n",
      "New instancia: 986\n",
      "York instancia: 986\n",
      "FRASL instancia: 1065\n",
      "FRASL instancia: 1197\n",
      "FRASL instancia: 1202\n",
      "FRASL instancia: 1229\n",
      "pornographic instancia: 1241\n",
      "FRASL instancia: 1307\n",
      "FRASL instancia: 1454\n",
      "FRASL instancia: 1454\n",
      "FRASL instancia: 1454\n",
      "FRASL instancia: 1454\n",
      "FRASL instancia: 1471\n",
      "FRASL instancia: 1585\n",
      "FRASL instancia: 1599\n",
      "FRASL instancia: 1630\n",
      "FRASL instancia: 1630\n",
      "FRASL instancia: 1684\n",
      "FRASL instancia: 1684\n",
      "FRASL instancia: 1684\n",
      "FRASL instancia: 1684\n",
      "FRASL instancia: 1684\n",
      "FRASL instancia: 1684\n",
      "FRASL instancia: 1752\n",
      "FRASL instancia: 1812\n",
      "FRASL instancia: 1867\n",
      "FRASL instancia: 1867\n",
      "FRASL instancia: 1962\n",
      "FRASL instancia: 1967\n",
      "FRASL instancia: 2001\n",
      "FRASL instancia: 2001\n",
      "FRASL instancia: 2006\n",
      "FRASL instancia: 2025\n",
      "FRASL instancia: 2135\n",
      "FRASL instancia: 2136\n",
      "FRASL instancia: 2138\n",
      "FRASL instancia: 2163\n",
      "FRASL instancia: 2169\n",
      "FRASL instancia: 2184\n",
      "FRASL instancia: 2185\n",
      "FRASL instancia: 2221\n",
      "FRASL instancia: 2230\n",
      "FRASL instancia: 2230\n",
      "FRASL instancia: 2258\n",
      "FRASL instancia: 2258\n",
      "FRASL instancia: 2271\n",
      "FRASL instancia: 2282\n",
      "FRASL instancia: 2285\n",
      "FRASL instancia: 2285\n",
      "FRASL instancia: 2294\n",
      "FRASL instancia: 2305\n",
      "FRASL instancia: 2306\n",
      "FRASL instancia: 2307\n",
      "FRASL instancia: 2308\n",
      "FRASL instancia: 2308\n",
      "FRASL instancia: 2308\n",
      "FRASL instancia: 2309\n",
      "FRASL instancia: 2309\n",
      "FRASL instancia: 2309\n",
      "FRASL instancia: 2309\n",
      "FRASL instancia: 2335\n",
      "FRASL instancia: 2336\n",
      "InternationalcurlyspaceBusinesscurlyspaceMachinescurlyspaceCorp instancia: 2382\n",
      ".,curlyspacethecurlyspacefirst-rankingcurlyspacesupplier instancia: 2382\n",
      "FRASL instancia: 2394\n",
      "FRASL instancia: 2413\n",
      "FRASL instancia: 2413\n",
      "FRASL instancia: 2416\n",
      "FRASL instancia: 2419\n",
      "FRASL instancia: 2419\n",
      "FRASL instancia: 2469\n",
      "FRASL instancia: 2476\n",
      "FRASL instancia: 2518\n",
      "FRASL instancia: 2518\n",
      "FRASL instancia: 2518\n",
      "FRASL instancia: 2541\n",
      "FRASL instancia: 2549\n",
      "FRASL instancia: 2564\n",
      "FRASL instancia: 2574\n",
      "FRASL instancia: 2621\n",
      "FRASL instancia: 2706\n",
      "FRASL instancia: 2707\n",
      "FRASL instancia: 2708\n",
      "FRASL instancia: 2718\n",
      "FRASL instancia: 2719\n",
      "FRASL instancia: 2719\n",
      "FRASL instancia: 2719\n",
      "FRASL instancia: 2730\n",
      "FRASL instancia: 2731\n",
      "FRASL instancia: 2754\n",
      "FRASL instancia: 2757\n",
      "FRASL instancia: 2759\n",
      "FRASL instancia: 2759\n",
      "FRASL instancia: 2760\n",
      "FRASL instancia: 2760\n",
      "FRASL instancia: 2761\n",
      "FRASL instancia: 2771\n",
      "FRASL instancia: 2772\n",
      "FRASL instancia: 2772\n",
      "FRASL instancia: 2774\n",
      "FRASL instancia: 2791\n",
      "FRASL instancia: 2791\n",
      "FRASL instancia: 2792\n",
      "FRASL instancia: 2793\n",
      "FRASL instancia: 2799\n",
      "FRASL instancia: 2809\n",
      "FRASL instancia: 2810\n",
      "FRASL instancia: 2811\n",
      "FRASL instancia: 2811\n",
      "FRASL instancia: 2835\n",
      "FRASL instancia: 2835\n",
      "FRASL instancia: 2843\n",
      "USG instancia: 2844\n",
      "'s instancia: 2844\n",
      "FRASL instancia: 2882\n",
      "FRASL instancia: 2889\n",
      "FRASL instancia: 2889\n",
      "FRASL instancia: 2918\n",
      "FRASL instancia: 2919\n",
      "FRASL instancia: 2919\n",
      "FRASL instancia: 2920\n",
      "FRASL instancia: 2924\n",
      "FRASL instancia: 2924\n",
      "FRASL instancia: 2926\n",
      "FRASL instancia: 2926\n",
      "FRASL instancia: 2926\n",
      "FRASL instancia: 2926\n",
      "FRASL instancia: 2936\n",
      "FRASL instancia: 2953\n",
      "FRASL instancia: 2955\n",
      "FRASL instancia: 2956\n",
      "FRASL instancia: 2956\n",
      "FRASL instancia: 2956\n",
      "FRASL instancia: 2957\n",
      "FRASL instancia: 2975\n",
      "FRASL instancia: 2978\n",
      "FRASL instancia: 2981\n",
      "FRASL instancia: 2995\n",
      "FRASL instancia: 2995\n",
      "FRASL instancia: 3008\n",
      "FRASL instancia: 3008\n",
      "FRASL instancia: 3011\n",
      "FRASL instancia: 3036\n",
      "FRASL instancia: 3054\n",
      "FRASL instancia: 3054\n",
      "FRASL instancia: 3057\n",
      "FRASL instancia: 3058\n",
      "FRASL instancia: 3081\n",
      "FRASL instancia: 3087\n",
      "FRASL instancia: 3091\n",
      "FRASL instancia: 3099\n",
      "FRASL instancia: 3102\n",
      "FRASL instancia: 3106\n",
      "FRASL instancia: 3124\n",
      "FRASL instancia: 3140\n",
      "FRASL instancia: 3142\n",
      "FRASL instancia: 3188\n",
      "FRASL instancia: 3207\n",
      "FRASL instancia: 3207\n",
      "FRASL instancia: 3248\n",
      "FRASL instancia: 3249\n",
      "FRASL instancia: 3253\n",
      "FRASL instancia: 3258\n",
      "FRASL instancia: 3262\n",
      "FRASL instancia: 3278\n",
      "FRASL instancia: 3290\n",
      "FRASL instancia: 3290\n",
      "FRASL instancia: 3305\n",
      "product instancia: 3306\n",
      "FRASL instancia: 3318\n",
      "FRASL instancia: 3320\n",
      "FRASL instancia: 3320\n",
      "FRASL instancia: 3323\n",
      "FRASL instancia: 3324\n",
      "FRASL instancia: 3325\n",
      "FRASL instancia: 3326\n",
      "FRASL instancia: 3337\n",
      "FRASL instancia: 3355\n",
      "FRASL instancia: 3356\n",
      "FRASL instancia: 3359\n",
      "FRASL instancia: 3360\n",
      "FRASL instancia: 3362\n",
      "FRASL instancia: 3362\n",
      "FRASL instancia: 3362\n",
      "FRASL instancia: 3367\n",
      "FRASL instancia: 3382\n",
      "FRASL instancia: 3425\n",
      "FRASL instancia: 3426\n",
      "FRASL instancia: 3477\n",
      "FRASL instancia: 3490\n",
      "FRASL instancia: 3513\n",
      "FRASL instancia: 3516\n",
      "FRASL instancia: 3526\n",
      "FRASL instancia: 3529\n",
      "FRASL instancia: 3529\n",
      "FRASL instancia: 3530\n",
      "FRASL instancia: 3530\n",
      "FRASL instancia: 3530\n",
      "FRASL instancia: 3538\n",
      "FRASL instancia: 3539\n",
      "FRASL instancia: 3539\n",
      "FRASL instancia: 3547\n",
      "FRASL instancia: 3551\n",
      "FRASL instancia: 3568\n",
      "FRASL instancia: 3589\n",
      "FRASL instancia: 3592\n",
      "FRASL instancia: 3619\n",
      "FRASL instancia: 3621\n",
      "FRASL instancia: 3623\n",
      "FRASL instancia: 3624\n",
      "FRASL instancia: 3624\n",
      "FRASL instancia: 3625\n",
      "FRASL instancia: 3625\n",
      "FRASL instancia: 3625\n",
      "FRASL instancia: 3680\n",
      "Mrs instancia: 3686\n",
      ". instancia: 3686\n",
      "FRASL instancia: 3698\n",
      "FRASL instancia: 3698\n",
      "FRASL instancia: 3708\n",
      "FRASL instancia: 3778\n",
      "She instancia: 3781\n",
      "is instancia: 3781\n",
      "FRASL instancia: 3802\n",
      "FRASL instancia: 3836\n",
      "FRASL instancia: 3935\n",
      "FRASL instancia: 3951\n",
      "FRASL instancia: 4076\n",
      "of instancia: 4136\n",
      "dialogue instancia: 4136\n",
      "Instancias en line.pos: [324, 391, 517, 559, 644, 681, 910, 986, 1065, 1197, 1202, 1229, 1241, 1307, 1454, 1471, 1585, 1599, 1630, 1684, 1752, 1812, 1867, 1962, 1967, 2001, 2006, 2025, 2135, 2136, 2138, 2163, 2169, 2184, 2185, 2221, 2230, 2258, 2271, 2282, 2285, 2294, 2305, 2306, 2307, 2308, 2309, 2335, 2336, 2382, 2394, 2413, 2416, 2419, 2469, 2476, 2518, 2541, 2549, 2564, 2574, 2621, 2706, 2707, 2708, 2718, 2719, 2730, 2731, 2754, 2757, 2759, 2760, 2761, 2771, 2772, 2774, 2791, 2792, 2793, 2799, 2809, 2810, 2811, 2835, 2843, 2844, 2882, 2889, 2918, 2919, 2920, 2924, 2926, 2936, 2953, 2955, 2956, 2957, 2975, 2978, 2981, 2995, 3008, 3011, 3036, 3054, 3057, 3058, 3081, 3087, 3091, 3099, 3102, 3106, 3124, 3140, 3142, 3188, 3207, 3248, 3249, 3253, 3258, 3262, 3278, 3290, 3305, 3306, 3318, 3320, 3323, 3324, 3325, 3326, 3337, 3355, 3356, 3359, 3360, 3362, 3367, 3382, 3425, 3426, 3477, 3490, 3513, 3516, 3526, 3529, 3530, 3538, 3539, 3547, 3551, 3568, 3589, 3592, 3619, 3621, 3623, 3624, 3625, 3680, 3686, 3698, 3708, 3778, 3781, 3802, 3836, 3935, 3951, 4076, 4136]\n",
      "Numero total de incosistencias en line.pos 176\n"
     ]
    }
   ],
   "source": [
    "# 'line.pos'\n",
    "instanciasconerror = encuentraIncongruenciasContexto('line.pos', True)\n",
    "print('Instancias en line.pos:', sorted(instanciasconerror))\n",
    "print('Numero total de incosistencias en line.pos', len(instanciasconerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instancias en serve.pos: [18, 24, 133, 150, 151, 214, 255, 275, 323, 412, 552, 607, 655, 664, 752, 762, 774, 881, 890, 956, 973, 1009, 1041, 1049, 1054, 1058, 1078, 1159, 1164, 1176, 1197, 1213, 1243, 1283, 1292, 1302, 1378, 1423, 1433, 1480, 1492, 1496, 1499, 1532, 1537, 1568, 1618, 1727, 1729, 1753, 1776, 1808, 1928, 1975, 2072, 2075, 2178, 2506, 2570, 2646, 2868, 2882, 3067, 3341, 3604, 3692, 3952, 3966, 4015, 4154, 4164, 4208, 4224, 4261, 4274, 4289]\n",
      "Numero total de incosistencias en serve.pos 76\n"
     ]
    }
   ],
   "source": [
    "# 'serve.pos'\n",
    "instanciasconerror = encuentraIncongruenciasContexto('serve.pos', False)\n",
    "print('Instancias en serve.pos:', sorted(instanciasconerror))\n",
    "print('Numero total de incosistencias en serve.pos', len(instanciasconerror))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Tienen todas las instancias que forman el corpus el formato que se ha descrito anteriormente? Si hay alguna instancia que no cumpla con ese formato, indica cuales serían las incongruencias que presenta.\n",
    "#### RESPUESTA \n",
    "**No**, si existen ecepciones, en todas las palabras ambiguas del corpus a ecepción de palabra line que no posee inconsistencias.  En **hard.pos** Existen **19 instancias** con incongruencias, es decir, que dentro de la lista de ese contexto no existe un par (tupla) conformado por la PALABRA y la ETIQUETA MORFOSINTACTICA POS **(palabra, POS)**. Adicionalmente en **hard.pos** todas las incosistencias son del mismo tipo, es decir aparece solo **'FRASL'** en medio del contexto, sin su correspondiente palabra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('wes', 'NNP'), ('raynal', 'NNP'), (',', ','), ('autoweek', 'NNP'), (';', ':'), ('(', '('), ('hbox', 'NN'), (')', 'SYM'), (';', ':'), ('``', '``'), ('low', 'NNP'), ('profiling', 'VBG'), ('is', 'VBZ'), ('pretty', 'RB'), ('hard', 'JJ'), ('in', 'IN'), ('a', 'DT'), ('car', 'NN'), ('this', 'DT'), ('bright', 'JJ'), (',', ','), ('a', 'DT'), ('characteristic', 'NN'), ('that', 'IN'), ('sets', 'VBZ'), ('the', 'DT'), ('r', 'NN'), 'FRASL', ('t', 'NN'), ('apart', 'RB'), ('from', 'IN'), ('the', 'DT'), ('taurus', 'NNP'), ('sho', 'NNP'), ('.', '.')] \n",
      "\n",
      "wes raynal , autoweek ; ( hbox ) ; `` low profiling is pretty hard in a car this bright , a characteristic that sets the r F t apart from the taurus sho . \n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de inconsistencia\n",
    "ins = senseval.instances('hard.pos')[110]\n",
    "print(ins.context,'\\n' )\n",
    "print(imprimeOracion(ins.context))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION DE ESTA ECEPCIÓN:** Aunque no domino perfectamentamente el idioma, puedo inferir que esta oración esta incompleta y tiene errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'DT'), ('boom', 'NN'), ('is', 'VBZ'), ('straining', 'VBG'), ('facilities', 'NNS'), ('.', '.'), ('\"', '\"'), ('if', 'IN'), ('you', 'PRP'), ('want', 'VBP'), ('to', 'TO'), ('tee', 'NN'), ('off', 'IN'), ('on', 'IN'), ('bethpage', 'NNP'), 'in', 'New', 'York', ('on', 'IN'), ('a', 'DT'), ('saturday', 'NNP'), ('morning', 'NN'), (',', ','), ('you', 'PRP'), ('have', 'VBP'), ('to', 'TO'), ('get', 'VB'), ('on', 'IN'), ('line', 'NN'), ('at', 'IN'), ('3', 'CD'), (':', ':'), ('30', 'CD'), ('a', 'DT'), ('.', '.'), ('m', 'NN'), ('.', '.'), ('or', 'CC'), ('4', 'CD'), ('a', 'DT'), ('.', '.'), ('m', 'NN'), ('.', '.'), (',', ','), ('\"', '\"'), ('says', 'VBZ'), ('charles', 'NNP'), ('robson', 'NNP'), (',', ','), ('of', 'IN'), ('the', 'DT'), ('metropolitan', 'NNP'), ('professional', 'NNP'), ('golfers', 'NNP'), ('association', 'NNP'), ('.', '.')] \n",
      "\n",
      "the boom is straining facilities . \" if you want to tee off on bethpage i N Y on a saturday morning , you have to get on line at 3 : 30 a . m . or 4 a . m . , \" says charles robson , of the metropolitan professional golfers association . \n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de inconsistencia\n",
    "ins = senseval.instances('line.pos')[986]\n",
    "print(ins.context,'\\n' )\n",
    "print(imprimeOracion(ins.context))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION DE ESTA ECEPCIÓN:** Al analizar esta ecepción claramente se puede ver que existen 3 palabras consecutivas en el contexto: 'in', 'New', 'York', que no poseen su correspondiente etiqueta POS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: extracción de características\n",
    "\n",
    "Para poder entrenar un clasificador es necesario extraer un conjunto de características lingüísticas a partir del corpus etiquetado. Por lo tanto, debes crear el código en Python que te permita extraer diferentes conjuntos de características a partir de Senseval 2. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debes extraer un **conjunto de características basado en las palabras vecinas**. Para una instancia del corpus, debes desarrollar el código que sea capaz de extraer el vector de características que indican si las palabras de un vocabulario aparecen o no en el contexto de la palabra ambigua."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando obtengas las palabras más frecuentes, debes eliminar los signos que puntuación y las palabras vacías (aquellas sin significado como artículos, pronombres o preposiciones, las llamadas stop words en inglés). También debes eliminar las diferentes formas gramaticales de la palabra ambigua, por ejemplo, para desambiguar la palabra *«hard»* no tendría sentido utilizar la palabra *«harder»* ni la palabra *«hardest»*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección 2.1 Funciones para encontrar las palabras más frecuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('time', 350),\n",
       " ('would', 252),\n",
       " ('get', 247),\n",
       " ('work', 245),\n",
       " ('find', 214),\n",
       " ('make', 214)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "# añado las formas gramaticales identificadas en la sección 1\n",
    "FORMAS_GRAMATICALES =[ 'harder', 'hardest', 'interests', 'lines', 'lined' 'serves', 'serving', 'served']\n",
    "OTHER_WORDS = [\"''\", \"'d\", \"'ll\", \"'m\", \"'re\", \"'s\", \"'t\", \"'ve\", '--', '000', '1', '10', '2', 'I', '``', 'also', \"don'\", 'n', 'one', 'said', 'say', 'says', 'us']\n",
    "EXCLUDED = set(OTHER_WORDS).union(set(FORMAS_GRAMATICALES))\n",
    "STOPWORDS_SET = set(stopwords.words('english')).union(set(string.punctuation), set(EXCLUDED))\n",
    "\n",
    "# obtengo las palabras mas frecuentes segun el parametro n \n",
    "# y el numero de ocurrencias de esa palabra\n",
    "def extraerFrequenciaVocab(instancias, stopwords=STOPWORDS_SET, n=10):\n",
    "    fd = nltk.FreqDist()\n",
    "    for i in instancias:\n",
    "        #excluyo tambien la palabra\n",
    "        (ambigua, sufijo) = i.word.split('-')\n",
    "        words = (c[0] for c in i.context if not c[0] == ambigua)\n",
    "        for word in set(words) - set(stopwords):\n",
    "            fd[word] += 1\n",
    "    return fd.most_common()[:n]\n",
    "\n",
    "# obtengo solo las palabras mas frecuentes sin el numero de ocurrencias\n",
    "def extraerSoloPalabras(instancias, stopwords=STOPWORDS_SET, n=10):\n",
    "    return [word for word,freq in extraerFrequenciaVocab(instancias,stopwords,n)]\n",
    "\n",
    "extraerFrequenciaVocab(senseval.instances('hard.pos'), STOPWORDS_SET, 6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección 2.2 Función para obtener el conjunto de características basado en las palabras vecinas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contains(time)': True,\n",
       " 'contains(would)': False,\n",
       " 'contains(get)': False,\n",
       " 'contains(work)': False,\n",
       " 'contains(find)': False,\n",
       " 'contains(make)': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masfrecuentes = extraerSoloPalabras(senseval.instances('hard.pos'), STOPWORDS_SET, 6)\n",
    "\n",
    "# funcion que devuelve un diccionario de caracteristicas basado en la frecuencia\n",
    "# y pertenencia un contexto\n",
    "def featuresFreqWords(instance, masfrecuentes):\n",
    "    features = {}\n",
    "    contexto = instance.context\n",
    "    for frecuente in masfrecuentes:\n",
    "        for word in contexto:\n",
    "            if frecuente == word[0]:\n",
    "                features['contains(' + frecuente + ')'] = True\n",
    "                break\n",
    "            else:\n",
    "                features['contains(' + frecuente + ')'] = False\n",
    "    return features\n",
    "\n",
    "#obtiene el conjunto de caracteristicas de la segunda instancia\n",
    "featuresFreqWords(senseval.instances('hard.pos')[1], masfrecuentes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección 2.3 Función para obtener el conjunto de características basado en la colocación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'previous(investors have a)': True, 'next(time identifying or)': True}\n",
      "{'previous(some)': True, 'next(choices had)': True}\n"
     ]
    }
   ],
   "source": [
    "# funcion que crea el conjunto de caracteristicas en base a la colocacion\n",
    "def featuresColocacion(instance, dist=2):\n",
    "    features = {}\n",
    "    posicion = instance.position\n",
    "    contexto = instance.context\n",
    "    grama = ''\n",
    "    #con la función max() evitamos el problema en los casos de que la palabra ambigua \n",
    "    # este muy al principio (posición 1 o 2) de la oración analizada.\n",
    "    for i in range(max(0, posicion - dist), posicion):\n",
    "        j = posicion-i\n",
    "        grama += contexto[i][0]\n",
    "        grama += ' '\n",
    "    features['previous(' + grama[:-1] + ')'] = True  # el limite [:-1] evita un espacio en blanco que se aumenta al iterar\n",
    "    grama = ''\n",
    "    #con la función min() evitamos el problema en los casos de que la palabra ambigua \n",
    "    # este muy al final (posición 1 o 2) de la oración analizada.\n",
    "    for i in range(posicion+1, min(posicion+dist+1, len(contexto))):\n",
    "        j = i-posicion\n",
    "        grama += contexto[i][0]\n",
    "        grama += ' '\n",
    "    features['next(' + grama[:-1] + ')'] = True\n",
    "    return features\n",
    "\n",
    "#Prueba 1 caso normal\n",
    "print(featuresColocacion(senseval.instances('hard.pos')[331], 3))\n",
    "#Prueba 2 caso en el cual no existen 2 palabras previas (al inicio de la oración)\n",
    "print(featuresColocacion(senseval.instances('hard.pos')[330], 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección 2.4  Tercer conjunto de características, Incorporar la información de las etiqueats morfosintácticas POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'previous(have a)': True,\n",
       " 'POS previous': 'VBP DT',\n",
       " 'next(time identifying)': True,\n",
       " 'POS next': 'NN VBG',\n",
       " 'POS': 'JJ'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MI PROPUESTA: Aumentar en el conjunto de caracteristicas la información de las etiquetas POS\n",
    "# tanto de las palabras previas, de las siguientes e inclusive de la palabra ambigua\n",
    "def featuresColocacionModif(instance, dist=2):\n",
    "    features = {}\n",
    "    posicion = instance.position\n",
    "    contexto = instance.context\n",
    "    grama = ''\n",
    "    wordsPOS = ''\n",
    "    for i in range(max(0, posicion - dist), posicion):\n",
    "        j = posicion-i\n",
    "        grama += contexto[i][0]\n",
    "        # esta es la etiqueta de la palabra iterada\n",
    "        wordsPOS += contexto[i][1] + ' '\n",
    "        if j ==dist:\n",
    "            grama += ' '\n",
    "    features['previous(' + grama + ')'] = True\n",
    "    features['POS previous'] = wordsPOS[:-1]\n",
    "    grama = ''\n",
    "    wordsPOS = ''\n",
    "    for i in range(posicion+1, min(posicion+dist+1, len(contexto))):\n",
    "        j = i-posicion\n",
    "        grama += contexto[i][0]\n",
    "        # esta es la etiqueta de la palabra iterada\n",
    "        wordsPOS += contexto[i][1] + ' '\n",
    "        if j <=dist-1:\n",
    "            grama += ' '\n",
    "    features['next(' + grama + ')'] = True\n",
    "    #se descarto esta notación ya que no se obtenia mejoras en el clasificador\n",
    "    # features['POS next(' + wordsPOS + ')'] = True  \n",
    "    features['POS next'] = wordsPOS[:-1]\n",
    "    \n",
    "    # Etiqueta POS de la palabra ambigua\n",
    "    features['POS'] = contexto[posicion][1]\n",
    "    #features['word'] = contexto[posicion][0]\n",
    "       \n",
    "    return features\n",
    "\n",
    "featuresColocacionModif(senseval.instances('hard.pos')[331], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3: entrenamiento de clasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador para:  hard.pos\n",
      "Tamaño de Conjunto de Train y Test:  3466 867\n",
      "\n",
      "**CLASIFICADOR PALABRAS VECINAS**\n",
      "Exactitud:  0.8535178777393311\n",
      "Actual:     HARD1\n",
      "Predicción:  HARD1\n",
      "\n",
      " Matriz de Confusión:\n",
      " \n",
      "      |   H   H   H |\n",
      "      |   A   A   A |\n",
      "      |   R   R   R |\n",
      "      |   D   D   D |\n",
      "      |   1   2   3 |\n",
      "------+-------------+\n",
      "HARD1 |<674> 14  10 |\n",
      "HARD2 |  42 <42>  1 |\n",
      "HARD3 |  58   2 <24>|\n",
      "------+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "**CLASIFICADOR BASADO EN COLOCACION**\n",
      "Exactitud:  0.8696655132641292\n",
      "Actual:     HARD1\n",
      "Predicted:  HARD1\n",
      "\n",
      " Matriz de Confusión:\n",
      " \n",
      "      |   H   H   H |\n",
      "      |   A   A   A |\n",
      "      |   R   R   R |\n",
      "      |   D   D   D |\n",
      "      |   1   2   3 |\n",
      "------+-------------+\n",
      "HARD1 |<673> 15  10 |\n",
      "HARD2 |  32 <52>  1 |\n",
      "HARD3 |  54   1 <29>|\n",
      "------+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "**CLASIFICADOR BASADO EN COLOCACION MEJORADO**\n",
      "Exactitud:  0.845444059976932\n",
      "Actual:     HARD2\n",
      "Predicted:  HARD2\n",
      "\n",
      " Matriz de Confusión:\n",
      " \n",
      "      |   H   H   H |\n",
      "      |   A   A   A |\n",
      "      |   R   R   R |\n",
      "      |   D   D   D |\n",
      "      |   1   2   3 |\n",
      "------+-------------+\n",
      "HARD1 |<619> 57  22 |\n",
      "HARD2 |  12 <66>  7 |\n",
      "HARD3 |  12  24 <48>|\n",
      "------+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Clasificador para:  interest.pos\n",
      "Tamaño de Conjunto de Train y Test:  1894 474\n",
      "\n",
      "**CLASIFICADOR PALABRAS VECINAS**\n",
      "Exactitud:  0.7805907172995781\n",
      "Actual:     interest_1\n",
      "Predicción:  interest_1\n",
      "\n",
      " Matriz de Confusión:\n",
      " \n",
      "           |   i   i   i   i   i   i |\n",
      "           |   n   n   n   n   n   n |\n",
      "           |   t   t   t   t   t   t |\n",
      "           |   e   e   e   e   e   e |\n",
      "           |   r   r   r   r   r   r |\n",
      "           |   e   e   e   e   e   e |\n",
      "           |   s   s   s   s   s   s |\n",
      "           |   t   t   t   t   t   t |\n",
      "           |   _   _   _   _   _   _ |\n",
      "           |   1   2   3   4   5   6 |\n",
      "-----------+-------------------------+\n",
      "interest_1 | <45>  .   4   6  10   5 |\n",
      "interest_2 |   4  <.>  .   1   .   1 |\n",
      "interest_3 |   2   .  <6>  .   2   . |\n",
      "interest_4 |   9   .   2 <22>  5   2 |\n",
      "interest_5 |  17   .   4   7 <73>  2 |\n",
      "interest_6 |   4   .   .   1  16<224>|\n",
      "-----------+-------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "**CLASIFICADOR BASADO EN COLOCACION**\n",
      "Exactitud:  0.6371308016877637\n",
      "Actual:     interest_5\n",
      "Predicted:  interest_5\n",
      "\n",
      " Matriz de Confusión:\n",
      " \n",
      "           |   i   i   i   i   i   i |\n",
      "           |   n   n   n   n   n   n |\n",
      "           |   t   t   t   t   t   t |\n",
      "           |   e   e   e   e   e   e |\n",
      "           |   r   r   r   r   r   r |\n",
      "           |   e   e   e   e   e   e |\n",
      "           |   s   s   s   s   s   s |\n",
      "           |   t   t   t   t   t   t |\n",
      "           |   _   _   _   _   _   _ |\n",
      "           |   1   2   3   4   5   6 |\n",
      "-----------+-------------------------+\n",
      "interest_1 | <18>  5   1   8  11  27 |\n",
      "interest_2 |   1  <.>  .   2   .   3 |\n",
      "interest_3 |   .   .  <5>  1   2   2 |\n",
      "interest_4 |   1   6   . <22>  2   9 |\n",
      "interest_5 |   1  16   2   6 <56> 22 |\n",
      "interest_6 |   .  36   2   3   3<201>|\n",
      "-----------+-------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "**CLASIFICADOR BASADO EN COLOCACION MEJORADO**\n",
      "Exactitud:  0.8037974683544303\n",
      "Actual:     interest_3\n",
      "Predicted:  interest_5\n",
      "\n",
      " Matriz de Confusión:\n",
      " \n",
      "           |   i   i   i   i   i   i |\n",
      "           |   n   n   n   n   n   n |\n",
      "           |   t   t   t   t   t   t |\n",
      "           |   e   e   e   e   e   e |\n",
      "           |   r   r   r   r   r   r |\n",
      "           |   e   e   e   e   e   e |\n",
      "           |   s   s   s   s   s   s |\n",
      "           |   t   t   t   t   t   t |\n",
      "           |   _   _   _   _   _   _ |\n",
      "           |   1   2   3   4   5   6 |\n",
      "-----------+-------------------------+\n",
      "interest_1 | <49>  3   .   6   5   7 |\n",
      "interest_2 |   1  <.>  .   2   .   3 |\n",
      "interest_3 |   .   1  <5>  1   2   1 |\n",
      "interest_4 |   2   .   3 <27>  7   1 |\n",
      "interest_5 |   8   2   3   7 <80>  3 |\n",
      "interest_6 |  10   9   2   .   4<220>|\n",
      "-----------+-------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Clasificador para:  line.pos\n",
      "Tamaño de Conjunto de Train y Test:  3316 830\n",
      "\n",
      "**CLASIFICADOR PALABRAS VECINAS**\n",
      "Exactitud:  0.6843373493975904\n",
      "Actual:     product\n",
      "Predicción:  formation\n",
      "\n",
      " Matriz de Confusión:\n",
      " \n",
      "          |           f             |\n",
      "          |       d   o             |\n",
      "          |       i   r       p     |\n",
      "          |       v   m       r     |\n",
      "          |       i   a   p   o     |\n",
      "          |   c   s   t   h   d   t |\n",
      "          |   o   i   i   o   u   e |\n",
      "          |   r   o   o   n   c   x |\n",
      "          |   d   n   n   e   t   t |\n",
      "----------+-------------------------+\n",
      "     cord | <52>  5   6   .   2   9 |\n",
      " division |  10 <36>  3   2  12  13 |\n",
      "formation |   8   7 <29>  5   8  12 |\n",
      "    phone |  16   .   4 <47> 10   2 |\n",
      "  product |   3  14  17  12<366> 28 |\n",
      "     text |  25  12   7   4   6 <38>|\n",
      "----------+-------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "**CLASIFICADOR BASADO EN COLOCACION**\n",
      "Exactitud:  0.7144578313253012\n",
      "Actual:     formation\n",
      "Predicted:  formation\n",
      "\n",
      " Matriz de Confusión:\n",
      " \n",
      "          |           f             |\n",
      "          |       d   o             |\n",
      "          |       i   r       p     |\n",
      "          |       v   m       r     |\n",
      "          |       i   a   p   o     |\n",
      "          |   c   s   t   h   d   t |\n",
      "          |   o   i   i   o   u   e |\n",
      "          |   r   o   o   n   c   x |\n",
      "          |   d   n   n   e   t   t |\n",
      "----------+-------------------------+\n",
      "     cord | <21>  .   4  11  37   1 |\n",
      " division |   1 <49>  3   4  18   1 |\n",
      "formation |   2   . <35>  5  26   1 |\n",
      "    phone |   2   4   . <48> 24   1 |\n",
      "  product |   6   3   7  11<408>  5 |\n",
      "     text |   2   2   2   1  53 <32>|\n",
      "----------+-------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "**CLASIFICADOR BASADO EN COLOCACION MEJORADO**\n",
      "Exactitud:  0.6927710843373494\n",
      "Actual:     product\n",
      "Predicted:  formation\n",
      "\n",
      " Matriz de Confusión:\n",
      " \n",
      "          |           f             |\n",
      "          |       d   o             |\n",
      "          |       i   r       p     |\n",
      "          |       v   m       r     |\n",
      "          |       i   a   p   o     |\n",
      "          |   c   s   t   h   d   t |\n",
      "          |   o   i   i   o   u   e |\n",
      "          |   r   o   o   n   c   x |\n",
      "          |   d   n   n   e   t   t |\n",
      "----------+-------------------------+\n",
      "     cord | <34>  6   1  11  18   4 |\n",
      " division |   1 <53>  2   6  11   3 |\n",
      "formation |   5   4 <38>  6  13   3 |\n",
      "    phone |   7   2   1 <51> 14   4 |\n",
      "  product |  14  17  10  26<362> 11 |\n",
      "     text |  11  12   3   3  26 <37>|\n",
      "----------+-------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Clasificador para:  serve.pos\n",
      "Tamaño de Conjunto de Train y Test:  3502 876\n",
      "\n",
      "**CLASIFICADOR PALABRAS VECINAS**\n",
      "Exactitud:  0.7442922374429224\n",
      "Actual:     SERVE2\n",
      "Predicción:  SERVE2\n",
      "\n",
      " Matriz de Confusión:\n",
      " \n",
      "        |   S   S         |\n",
      "        |   E   E   S   S |\n",
      "        |   R   R   E   E |\n",
      "        |   V   V   R   R |\n",
      "        |   E   E   V   V |\n",
      "        |   1   1   E   E |\n",
      "        |   0   2   2   6 |\n",
      "--------+-----------------+\n",
      "SERVE10 |<288> 11  60   2 |\n",
      "SERVE12 |   1<202> 54  11 |\n",
      " SERVE2 |  11  21<118> 13 |\n",
      " SERVE6 |   5   7  28 <44>|\n",
      "--------+-----------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "**CLASIFICADOR BASADO EN COLOCACION**\n",
      "Exactitud:  0.7328767123287672\n",
      "Actual:     SERVE10\n",
      "Predicted:  SERVE10\n",
      "\n",
      " Matriz de Confusión:\n",
      " \n",
      "        |   S   S         |\n",
      "        |   E   E   S   S |\n",
      "        |   R   R   E   E |\n",
      "        |   V   V   R   R |\n",
      "        |   E   E   V   V |\n",
      "        |   1   1   E   E |\n",
      "        |   0   2   2   6 |\n",
      "--------+-----------------+\n",
      "SERVE10 |<331> 21   6   3 |\n",
      "SERVE12 |  63<182> 21   2 |\n",
      " SERVE2 |  36  14<110>  3 |\n",
      " SERVE6 |  53   3   9 <19>|\n",
      "--------+-----------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "**CLASIFICADOR BASADO EN COLOCACION MEJORADO**\n",
      "Exactitud:  0.7831050228310502\n",
      "Actual:     SERVE10\n",
      "Predicted:  SERVE10\n",
      "\n",
      " Matriz de Confusión:\n",
      " \n",
      "        |   S   S         |\n",
      "        |   E   E   S   S |\n",
      "        |   R   R   E   E |\n",
      "        |   V   V   R   R |\n",
      "        |   E   E   V   V |\n",
      "        |   1   1   E   E |\n",
      "        |   0   2   2   6 |\n",
      "--------+-----------------+\n",
      "SERVE10 |<293> 30  15  23 |\n",
      "SERVE12 |  14<225> 22   7 |\n",
      " SERVE2 |  14  21<123>  5 |\n",
      " SERVE6 |  19   5  15 <45>|\n",
      "--------+-----------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import accuracy, NaiveBayesClassifier\n",
    "import random\n",
    "\n",
    "# Funcion que genera los conjuntos de entrenamiento y test \n",
    "# en la proporcion 80%, 20%\n",
    "def generarData(amb_word):\n",
    "    conjunto = {}\n",
    "    conjunto[amb_word] = [(i, i.senses[0]) for i in senseval.instances(amb_word)]\n",
    "    events = conjunto[amb_word][:]\n",
    "\n",
    "    # se mezcla las instancias para garantizar que en los conjuntos, no vengan juntos las mismas categorias de la palabra ambigua\n",
    "    n = len(events)\n",
    "    random.seed(72448)\n",
    "    random.shuffle(events)\n",
    "    training_data = events[:int(0.8 * n)]\n",
    "    test_data = events[int(0.8 * n):n]\n",
    "\n",
    "    return training_data, test_data\n",
    "\n",
    "# Genera los 3 clasificadores para cada palabra\n",
    "def generaClasificadores(amb_word):\n",
    "    \n",
    "    print ('Clasificador para: ', amb_word )\n",
    "    # Estos conjuntos permaneceran constantes para los 3 clasificadores\n",
    "    # obtengo conjuntos de entrenamiento (X) y test (X_t)\n",
    "    X, X_t = generarData(amb_word)\n",
    "    print ('Tamaño de Conjunto de Train y Test: ', len(X), len(X_t))\n",
    "\n",
    "    #Primer clasificador basado en palabras vecinas \n",
    "    freqWords = extraerSoloPalabras(senseval.instances(amb_word), STOPWORDS_SET, 250)\n",
    "    featuresets_train = [(featuresFreqWords(d, freqWords), c) for (d,c) in X]\n",
    "    featuresets_test = [(featuresFreqWords(d, freqWords), c) for (d,c) in X_t]\n",
    "\n",
    "    classifier1 = NaiveBayesClassifier.train(featuresets_train)\n",
    "    print('\\n**CLASIFICADOR PALABRAS VECINAS**')\n",
    "    print('Exactitud: ',accuracy(classifier1, featuresets_test))\n",
    "\n",
    "    # Predicción de una instancia\n",
    "    print ('Actual:    ', X_t[20][1])\n",
    "    print ('Predicción: ', classifier1.classify(featuresFreqWords(X_t[20][0], freqWords)))\n",
    "\n",
    "    # Predicción de todas las instancias de los datos de Test \n",
    "    # para el calculo de la matriz de confusión\n",
    "    actual = [cat for (i, cat) in X_t]  # variable que contiene el valor real del conjunto de test\n",
    "    prediccion1 = [classifier1.classify(featuresFreqWords(ins,freqWords)) for (ins,label) in X_t]\n",
    "\n",
    "    print('\\n Matriz de Confusión:\\n ' )\n",
    "    print(nltk.ConfusionMatrix(actual,prediccion1))\n",
    "\n",
    "    #Segundo clasificador basado en la colocacion de las palabras\n",
    "    featuresets_train_2 = [(featuresColocacion(d, 2), c) for (d,c) in X]\n",
    "    featuresets_test_2 = [(featuresColocacion(d, 2), c) for (d,c) in X_t]\n",
    "\n",
    "    classifier2 = NaiveBayesClassifier.train(featuresets_train_2)\n",
    "    print('\\n**CLASIFICADOR BASADO EN COLOCACION**')\n",
    "    print('Exactitud: ', accuracy(classifier2, featuresets_test_2))\n",
    "\n",
    "    # Predicción de una instancia\n",
    "    print ('Actual:    ', X_t[40][1])\n",
    "    print ('Predicted: ', classifier2.classify(featuresColocacion(X_t[40][0],2)))\n",
    "\n",
    "    prediccion2 = [classifier2.classify(featuresColocacion(ins,2)) for (ins,label) in X_t]\n",
    "\n",
    "    print('\\n Matriz de Confusión:\\n ' )\n",
    "    print(nltk.ConfusionMatrix(actual,prediccion2))\n",
    "\n",
    "    #Tercer clasificador basado en la colocacion de las palabras \n",
    "    #pero el vector de caracteristicas incluye la etiqueta POS\n",
    "    featuresets_train_3 = [(featuresColocacionModif(d, 2), c) for (d,c) in X]\n",
    "    featuresets_test_3 = [(featuresColocacionModif(d, 2), c) for (d,c) in X_t]\n",
    "\n",
    "    classifier3 = NaiveBayesClassifier.train(featuresets_train_3)\n",
    "    print('\\n**CLASIFICADOR BASADO EN COLOCACION MEJORADO**')\n",
    "    print('Exactitud: ', accuracy(classifier3, featuresets_test_3))\n",
    "\n",
    "    # Predicción de una instancia\n",
    "    print ('Actual:    ', X_t[50][1])\n",
    "    print ('Predicted: ', classifier3.classify(featuresColocacionModif(X_t[40][0],2)))\n",
    "\n",
    "    prediccion3 = [classifier3.classify(featuresColocacionModif(ins,2)) for (ins,label) in X_t]\n",
    "\n",
    "    print('\\n Matriz de Confusión:\\n ' )\n",
    "    print(nltk.ConfusionMatrix(actual,prediccion3))\n",
    "    \n",
    "generaClasificadores('hard.pos')\n",
    "generaClasificadores('interest.pos')\n",
    "generaClasificadores('line.pos')\n",
    "generaClasificadores('serve.pos')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analiza los resultados del rendimiento con base en la exactitud (accuracy) y la matriz de confusión, obtenidos para cada uno de los tres clasificadores que permiten desambiguar el sentido de la palabra «hard»."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responde a las siguientes preguntas:\n",
    "\n",
    "* ¿Cuál es el conjunto de características que aporta mejores resultados? ¿Por qué? \n",
    "\n",
    "* ¿Cuál es el sentido más difícil de identificar? ¿Por qué?\n",
    "\n",
    "* ¿Qué posibles mejoras se podrían aplicar para mejorar el rendimiento de los clasificadores creados? No es necesario que las implementes, solo que las comentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el clasificador que permite desambiguar la palabra «hard» y que utiliza las características de colocación, obtén las instancias que pertenecen al sentido ‘HARD1’ y que se han clasificado incorrectamente. Presenta en el informe la oración en la que aparece la palabra ambigua (el contexto) para cada una de esas instancias y la etiqueta en la que han sido erróneamente clasificadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, entrena algunos clasificadores que te permitan desambiguar el resto de las palabras ambiguas «interest», «line» y «serve». Crea tres clasificadores para cada palabra ambigua manteniendo los mismos parámetros que en la extracción de características (m=250 para las características basadas en las palabras vecinas y n=2 para las características de colocación) y la proporción del 80-20 % para la creación de los conjuntos de entrenamiento y de test. Compara los resultados de rendimiento basados en la exactitud (accuracy) para los clasificadores que has creado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presenta en el informe los valores de exactitud para cada uno de los 12 clasificadores (tres para cada palabra ambigua) y responde a las siguientes preguntas:\n",
    "\n",
    "* ¿Por qué no es justo comparar directamente la exactitud aportada por los clasificadores que han aprendido diferentes palabras ambiguas?\n",
    "\n",
    "* ¿Cómo podrías hacerlo para que la comparación entre clasificadores que desambiguan palabras diferentes tenga sentido?\n",
    "\n",
    "* Compara la exactitud de los clasificadores con la que proporcionaría un clasificador que asignara el sentido de forma aleatoria. ¿Cuál sería el mejor clasificador tomando como referencia (baseline), el clasificador aleatorio?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4: conclusiones sobre el uso de aprendizaje automático supervisado para desambiguar el sentido de las palabras\n",
    "\n",
    "Una vez hayas implementado diferentes clasificadores para desambiguar el sentido de diferentes palabras y analizado su desempeño, reflexiona sobre el uso de algoritmos basados en aprendizaje automático supervisado para resolver la tarea de desambiguación del sentido de las palabras. Para ello responde de forma razonada a las siguientes preguntas:\n",
    "\n",
    "* ¿Cuáles son las limitaciones de los clasificadores que has creado para la desambiguación del sentido de las palabras?\n",
    "\n",
    "* ¿Qué alternativas propondrías para superar esas limitaciones y obtener algoritmo que resuelva mejor el problema de la desambiguación del sentido de las palabras?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
